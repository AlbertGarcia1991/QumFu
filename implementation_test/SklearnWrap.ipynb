{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test implementation on 2D to 1D problems\n",
    "### Problem Setup\n",
    "To start testing the algorithm, we are going to try to optimize finding the absolute minima of a function with\n",
    "one input and one output. Lets start defining this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import warnings\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from scipy.stats import norm\n",
    "\n",
    "plt.style.use('dark_background')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Implementation of the same algorithm using out own tool\n",
    "from search_space import InputValueSpace, SearchSpace, choice, integer_random, transform_exp_base_10, static, float_random\n",
    "from evaluation_metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Union\n",
    "import micromlgen\n",
    "\n",
    "# objective function is to MAXIMIZE the value of the function\n",
    "class ObjectiveFunction:\n",
    "    def __init__(self, model: LogisticRegression, base_toi: int, metric: callable, metric_args: list = None,\n",
    "                 constraints: dict = None):\n",
    "        self.name = self.__class__.__name__\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.metric_args = {\"model_size\": 3000, \"model_latency\": 200} if metric_args is None else metric_args\n",
    "        self.model_latency = base_toi\n",
    "        self.constaints = constraints\n",
    "\n",
    "        if model.__module__.split(\".\")[0] == \"sklearn\":\n",
    "            self.model_framework = \"sklearn\"\n",
    "            self.model_family = model.__module__.split(\".\")[1]\n",
    "            self.model_type = model.__module__.split(\".\")[2]\n",
    "        elif model.__module__.split(\".\")[0] == \"keras\":\n",
    "            self.model_framework = \"keras\"\n",
    "            self.model_family = model.__module__.split(\".\")[1]\n",
    "            self.model_type = None\n",
    "        else:\n",
    "            raise NotImplementedError(\"The given model type has not been implemented yet\")\n",
    "\n",
    "        self.trained = False\n",
    "        self.history_params = []\n",
    "        self.history_outputs = []\n",
    "        self.history_metrics = []\n",
    "\n",
    "    def train(self, X: np.ndarray, Y: np.ndarray):\n",
    "        self.model.fit(X, Y)\n",
    "        self.trained = True\n",
    "\n",
    "    def predict(self, x: np.ndarray, append: bool = True) -> Union[list, float]:\n",
    "        assert self.trained, ValueError(\"Model not trained yet\")  # TODO: Add custom error\n",
    "        if not isinstance(x, np.ndarray):\n",
    "            x = np.ndarray(x)\n",
    "        if x.ndim == self.model.n_features_in_:\n",
    "            pred = self.model.predict(np.expand_dims(x, axis=0))\n",
    "        else:\n",
    "            raise ValueError(\"Dimensions not matching\")  # TODO: Add custom error\n",
    "        if append:\n",
    "            self.history_outputs.append(pred)\n",
    "        return pred\n",
    "\n",
    "    def set_parameters(self, params: dict, append: bool = True):\n",
    "        if self.model_framework == \"sklearn\":\n",
    "            self.model.set_params(**params)\n",
    "        elif self.model_framework == \"keras\":\n",
    "            # TODO\n",
    "            pass\n",
    "\n",
    "        if append:\n",
    "            self.history_params.append(params)\n",
    "        self.model_serialized = self.get_model_serialized()\n",
    "        self.model_size = self.get_model_size()\n",
    "        self.model_latency += self.get_computing_toi()\n",
    "        if self.constaints[\"model_size\"] <= self.model_size or self.constaints[\"model_latency\"] <= self.model_latency:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def get_parameters(self) -> dict:\n",
    "        # TODO: Test this method for Keras models\n",
    "        return self.model.get_params()\n",
    "\n",
    "    def predict_evaluate(self, x: np.ndarray, y: np.ndarray, append: bool = True) -> float:\n",
    "        if not isinstance(x, np.ndarray):\n",
    "            x = np.ndarray(x)\n",
    "        goal = self.evaluate(self.model.score(x, y))\n",
    "        if append:\n",
    "            self.history_metrics.append(goal)\n",
    "        return goal\n",
    "\n",
    "    def get_model_serialized(self):\n",
    "        # TODO\n",
    "        return 0\n",
    "\n",
    "    def get_model_size(self):\n",
    "        # TODO\n",
    "        return 0\n",
    "\n",
    "    def get_computing_toi(self):\n",
    "        # TODO\n",
    "        return 0\n",
    "\n",
    "    def evaluate(self, y: np.ndarray):\n",
    "        return self.metric([y, self.model_size, self.model_latency], self.metric_args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "def random_search_optimization(X_train: np.ndarray,\n",
    "                               X_test: np.ndarray,\n",
    "                               y_train: np.ndarray,\n",
    "                               y_test: np.ndarray,\n",
    "                               search_space: SearchSpace,\n",
    "                               f: ObjectiveFunction,\n",
    "                               n_iters: int = 100,\n",
    "                               ):\n",
    "    for _ in range(n_iters):\n",
    "        search_space.sample()\n",
    "        constraints_flag = obj.set_parameters(se.current)\n",
    "        if constraints_flag:\n",
    "            obj.train(X_train, y_train)\n",
    "            obj.predict_evaluate(X_test, y_test)\n",
    "    return f"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "\n",
    "X = data[\"data\"]\n",
    "y = data[\"target\"]\n",
    "\n",
    "n_iters = 10\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlbertGarciaPlaza\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\AlbertGarciaPlaza\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\AlbertGarciaPlaza\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\AlbertGarciaPlaza\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\AlbertGarciaPlaza\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\AlbertGarciaPlaza\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\AlbertGarciaPlaza\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\AlbertGarciaPlaza\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "se_logistic_regression_dict = {\n",
    "    \"penalty\": InputValueSpace(\n",
    "        se_type=choice, params_dict={\"options\": [\"none\", \"elasticnet\"]}\n",
    "    ),\n",
    "    \"C\": InputValueSpace(\n",
    "        se_type=integer_random, params_dict={\n",
    "            \"lower_bound\": -3, \"upper_bound\": 2, \"lambda_function\": transform_exp_base_10}\n",
    "    ),\n",
    "    \"solver\": InputValueSpace(\n",
    "        se_type=static, params_dict={\"value\": \"saga\"}\n",
    "    ),\n",
    "    \"max_iter\": InputValueSpace(\n",
    "        se_type=static, params_dict={\"value\": 500}\n",
    "    ),\n",
    "    \"l1_ratio\": InputValueSpace(\n",
    "        se_type=float_random, params_dict={\"lower_bound\": 0, \"upper_bound\": 1}\n",
    "    )\n",
    "}\n",
    "se = SearchSpace(input_dict=se_logistic_regression_dict, conditions_dict={\"l1_ratio\": [\"penalty\", \"eq\", \"elasticnet\"]})\n",
    "\n",
    "obj = ObjectiveFunction(model=LogisticRegression(), metric=weighted_score, base_toi=0, metric_args=[0.8, 0.1, 0.1])\n",
    "\n",
    "explored_space = random_search_optimization(X_train=X_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_train,\n",
    "                                            y_test=y_test,\n",
    "                                            search_space=se,\n",
    "                                            f=obj,\n",
    "                                            n_iters=n_iters\n",
    "                                            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [
    {
     "data": {
      "text/plain": "'sklearn.linear_model._logistic'"
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.__module__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "clf2 = tf.keras.Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "data": {
      "text/plain": "'keras.engine.sequential'"
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.__module__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-dc3a814d",
   "language": "python",
   "display_name": "PyCharm (hypertuning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}